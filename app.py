import streamlit as st
from langchain.llms import Ollama
from langchain.embeddings import OllamaEmbeddings
from sentence_transformers import SentenceTransformer
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from pypdf import PdfReader

# Models
llm = Ollama(model="qwen2.5:1.5b")
embed_model = OllamaEmbeddings(model="bge-m3")

st.title("ğŸ“š NLP AI Assistant â€” RAG + Summary + Rewrite")

uploaded_file = st.file_uploader("ä¸Šå‚³ PDF/TXT æ–‡ä»¶", type=["pdf", "txt"])

if uploaded_file:
    st.success("æ–‡ä»¶å·²ä¸Šå‚³ï¼Œæ­£åœ¨è™•ç†...")

    text = ""

    if uploaded_file.type == "application/pdf":
        pdf = PdfReader(uploaded_file)
        for page in pdf.pages:
            text += page.extract_text()
    else:
        text = uploaded_file.read().decode("utf-8")

    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    chunks = splitter.split_text(text)

    db = Chroma.from_texts(chunks, embed_model)

    option = st.selectbox(
        "é¸æ“‡æ¨¡å¼",
        ["å•ç­”æ¨¡å¼", "æ‘˜è¦æ¨¡å¼", "æ–‡é¢¨æ”¹å¯«æ¨¡å¼"]
    )

    user_input = st.text_input("è¼¸å…¥å•é¡Œ / å¥å­ï¼š")

    if st.button("åŸ·è¡Œ"):
        if option == "å•ç­”æ¨¡å¼":
            docs = db.similarity_search(user_input, k=3)
            context = "\n".join([d.page_content for d in docs])
            prompt = f"æ ¹æ“šä»¥ä¸‹å…§å®¹å›ç­”ï¼š\n{context}\n\nå•é¡Œï¼š{user_input}\nå›ç­”ï¼š"
            st.write(llm(prompt))

        elif option == "æ‘˜è¦æ¨¡å¼":
            prompt = f"è«‹ç”¨ç¹é«”ä¸­æ–‡æ‘˜è¦ä»¥ä¸‹å…§å®¹ï¼š\n{text[:2000]}..."
            st.write(llm(prompt))

        elif option == "æ–‡é¢¨æ”¹å¯«æ¨¡å¼":
            prompt = f"è«‹å°‡ä»¥ä¸‹æ–‡å­—æ”¹ç‚ºæ›´è‡ªç„¶ä½†æ­£å¼çš„èªæ°£ï¼š\n{user_input}"
            st.write(llm(prompt))
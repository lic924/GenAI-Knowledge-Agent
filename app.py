import streamlit as st
import numpy as np
from pypdf import PdfReader
from sentence_transformers import SentenceTransformer
from transformers import pipeline

# ========== è¨­å®šé é¢ ==========
st.set_page_config(page_title="GenAI Knowledge Agent", page_icon="ğŸ¤–")
st.title("ğŸ¤– GenAI Knowledge Agent")
st.subheader("RAG + Summarization + Style Rewrite")

# ========== åˆå§‹åŒ–æ¨¡å‹ï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡è¼‰å…¥æ™‚åšï¼‰ ==========
@st.cache_resource
def load_models():
    # åµŒå…¥æ¨¡å‹ï¼Œç”¨æ–¼ RAG æª¢ç´¢
    embedder = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
    # å°å‹ç”Ÿæˆæ¨¡å‹ï¼ˆè‹±æ–‡è¼ƒå¼·ï¼Œä½†ä¹Ÿèƒ½è™•ç†ä¸€äº›ä¸­æ–‡ï¼‰
    gen_pipe = pipeline(
        "text2text-generation",
        model="google/flan-t5-small"
    )
    return embedder, gen_pipe

embedder, gen_pipe = load_models()

# ========== Session State ==========
if "chunks" not in st.session_state:
    st.session_state["chunks"] = []
if "embeddings" not in st.session_state:
    st.session_state["embeddings"] = None
if "full_text" not in st.session_state:
    st.session_state["full_text"] = ""

# ========== å·¥å…·å‡½å¼ ==========
def load_text(file):
    if file.type == "application/pdf":
        reader = PdfReader(file)
        return "\n".join([page.extract_text() or "" for page in reader.pages])
    else:
        return file.read().decode("utf-8")

def chunk_text(text, chunk_size=400, overlap=50):
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunks.append(text[start:end])
        start = end - overlap
    return chunks

def build_index(text):
    chunks = chunk_text(text)
    embeddings = embedder.encode(chunks, convert_to_numpy=True)
    st.session_state["chunks"] = chunks
    st.session_state["embeddings"] = embeddings

def retrieve_context(query, k=3):
    if st.session_state["embeddings"] is None:
        return ""
    q_emb = embedder.encode([query], convert_to_numpy=True)[0]
    emb = st.session_state["embeddings"]

    # cosine similarity
    dot = emb @ q_emb
    norm_emb = np.linalg.norm(emb, axis=1)
    norm_q = np.linalg.norm(q_emb)
    scores = dot / (norm_emb * norm_q + 1e-10)

    top_idx = np.argsort(scores)[::-1][:k]
    selected = [st.session_state["chunks"][i] for i in top_idx]
    return "\n\n".join(selected)

def generate(text, max_new_tokens=256):
    # ç”¨ flan-t5-small åš text2text generation
    out = gen_pipe(
        text,
        max_new_tokens=max_new_tokens,
        do_sample=False
    )
    return out[0]["generated_text"].strip()

# ========== æª”æ¡ˆä¸Šå‚³ ==========
uploaded_file = st.file_uploader("ğŸ“ ä¸Šå‚³ PDF æˆ– TXT æ–‡ä»¶", type=["pdf", "txt"])

if uploaded_file:
    st.success("æ–‡ä»¶å·²ä¸Šå‚³ï¼Œæ­£åœ¨å»ºç«‹ç´¢å¼•ï¼ˆé¦–æ¬¡å¯èƒ½è¼ƒæ…¢ï¼‰...")
    full_text = load_text(uploaded_file)
    st.session_state["full_text"] = full_text
    build_index(full_text)
    st.info(f"æ–‡ä»¶é•·åº¦ï¼šç´„ {len(full_text)} å­—å…ƒï¼Œchunk æ•¸é‡ï¼š{len(st.session_state['chunks'])}")
else:
    full_text = st.session_state["full_text"]

# ========== æ¨¡å¼é¸å–® ==========
modes = ["ğŸ“Œ å•ç­”æ¨¡å¼ï¼ˆRAGï¼‰", "ğŸ“ æ‘˜è¦æ¨¡å¼", "âœï¸ æ–‡é¢¨æ”¹å¯«æ¨¡å¼"]
selected_mode = st.radio("é¸æ“‡åŠŸèƒ½æ¨¡å¼ï¼š", modes)

user_input = st.text_input("è¼¸å…¥å•é¡Œ / è¦æ”¹å¯«çš„æ–‡å­—ï¼š")

tone = None
if selected_mode == "âœï¸ æ–‡é¢¨æ”¹å¯«æ¨¡å¼":
    tone = st.selectbox(
        "é¸æ“‡æ–‡é¢¨ï¼š",
        ["æ­£å¼", "å­¸è¡“", "å£èª", "ç°¡æ½”æ‘˜è¦", "å¯æ„›é¢¨"]
    )

# ========== åŸ·è¡ŒæŒ‰éˆ• ==========
if st.button("ğŸš€ åŸ·è¡Œä»»å‹™"):

    # 1) å•ç­”æ¨¡å¼ï¼ˆRAGï¼‰
    if selected_mode.startswith("ğŸ“Œ"):
        if not uploaded_file and not st.session_state["chunks"]:
            st.error("è«‹å…ˆä¸Šå‚³æ–‡ä»¶ï¼")
        elif not user_input:
            st.error("è«‹è¼¸å…¥å•é¡Œã€‚")
        else:
            context = retrieve_context(user_input, k=3)
            prompt = (
                "ä½ æ˜¯ä¸€å€‹æ–‡ä»¶åŠ©ç†ï¼Œè«‹æ ¹æ“šä¸‹åˆ—å…§å®¹å›ç­”å•é¡Œï¼Œ"
                "ç›¡é‡ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¸¦ç°¡çŸ­æ‰¼è¦ã€‚\n\n"
                f"[æ–‡ä»¶å…§å®¹]\n{context}\n\n"
                f"[å•é¡Œ]\n{user_input}\n\n"
                "å›ç­”ï¼š"
            )
            answer = generate(prompt, max_new_tokens=256)
            st.markdown("### ğŸ§  å›ç­”")
            st.write(answer)

    # 2) æ‘˜è¦æ¨¡å¼
    elif selected_mode.startswith("ğŸ“"):
        if not full_text:
            st.error("è«‹å…ˆä¸Šå‚³æ–‡ä»¶ï¼")
        else:
            prompt = (
                "è«‹å°‡ä»¥ä¸‹æ–‡å­—é‡é»å¼ç¸½çµï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œæ¢åˆ— 5~8 é»ï¼š\n\n"
                f"{full_text[:6000]}"
            )
            summary = generate(prompt, max_new_tokens=256)
            st.markdown("### ğŸ“ æ‘˜è¦çµæœ")
            st.write(summary)

    # 3) æ–‡é¢¨æ”¹å¯«æ¨¡å¼
    elif selected_mode.startswith("âœï¸"):
        if not user_input:
            st.error("è«‹å…ˆè¼¸å…¥è¦æ”¹å¯«çš„æ–‡å­—ã€‚")
        else:
            prompt = (
                f"è«‹å°‡ä»¥ä¸‹æ–‡å­—æ”¹å¯«æˆã€Œ{tone}ã€é¢¨æ ¼ï¼Œ"
                "ä¸¦ä½¿ç”¨ç¹é«”ä¸­æ–‡è¼¸å‡ºï¼š\n\n"
                f"{user_input}"
            )
            rewritten = generate(prompt, max_new_tokens=256)
            st.markdown("### âœï¸ æ”¹å¯«çµæœ")
            st.write(rewritten)